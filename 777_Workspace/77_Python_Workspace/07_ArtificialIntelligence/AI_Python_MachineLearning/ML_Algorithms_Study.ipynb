{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms\n",
    "## 1. Regression\n",
    "- Linear Regression (선형 회귀)\n",
    "- Stochastic Gradient Descent Regression (SGD 회귀)\n",
    "- SVR, Support Vector Regression (서포트 벡터 회귀)\n",
    "- Random Forest Regression (랜덤 포레스트 회귀)\n",
    "- Bayesian Regression (베이지안 회귀)\n",
    "- Isotonic Regression (등위 회귀)\n",
    "\n",
    "## 2. Classification\n",
    "- Logistic Regression (로지스틱 회귀)\n",
    "- SVM, Support Vector Machine (서포트 ㅂ벡터 머신)\n",
    "- Random Forest (랜덤 포레스트)\n",
    "- Decision Tree (의사결정 트리)\n",
    "- GBT, Gradient Boosting Tree (그레디언트 부스팅 트리)\n",
    "- SGD Classifier (SGD 분류기)\n",
    "- AdaBoost\n",
    "\n",
    "## 3. Clustering\n",
    "- K-means (K-평균)\n",
    "- Spectral Clustering (스펙트럼 군집화)\n",
    "- Gaussian Mixtures (가우시안 혼합)\n",
    "- Agglomerative Clustering (병합식 군집화)\n",
    "- Affinity Propagation (친근도 전파)\n",
    "- Mean Shift (평균 이동)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression\n",
    "데이터를 가장 잘 대표하는 선형 방정식의 기울기(coefficient)와 절편(intercept)를 구하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_data_df = pd.DataFrame(iris.data)\n",
    "iris_data_df.columns = [iris.feature_names]\n",
    "\n",
    "iris_target_df = pd.DataFrame(iris.target)\n",
    "iris_target_df.columns = ['species']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data_df, iris_target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9494903032134198\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "accuracy = model.score(x_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 KNN (k-최근접 이웃, K-Nearest Neighbors)\n",
    "\n",
    "- 거리 측정(DIstance measurement)하여 분류\n",
    "- 원리 : Label이 없는 데이터가 주어졌을 때, 기존의 모든 데이터와 새로운 데이터를 비교하여 가장 유사한 데이터(=가장 근접한 이웃) 상위 K개의 majority voting\n",
    "- 장단점 :  높은 정확도 및 outlier잘 견딤, 데이터에 대한 가정이 없는 장점이 있으나, 높은 계산 비용과 메모리 요구 됨\n",
    "- 사용 : 수치형 값, 명목형 값에 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_KNN = KNeighborsClassifier(n_neighbors= 3)\n",
    "model_KNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model_KNN.score(x_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Support Vector Machine (SVM)\n",
    "퍼셉트론 + 가장 안정적인 판별 경계선을 찾기 추가\n",
    "- 원리 : 구분을 위한 라인이나 평면을 찾는다\n",
    "- 장단점 : 과적합에 강한 성능을 보이며 성능이 우수하다. 하지만, 모델 생성 시간이 길어질 수 있으며, 모델을 해석하기 어렵다.\n",
    "- 사용 : 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "model_SVC = SVC()\n",
    "model_SVC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_SVC.predict(x_test)\n",
    "accuracy = model_SVC.score(x_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Random Forest\n",
    "- 원리 : 앙상블 학습 방법의 일종으로 다수의 결정 트리로부터 분류 혹은 회귀 분석\n",
    "- 장단점 :  \n",
    "- 사용 : 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier()\n",
    "model_RF.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model_RF.score(x_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 K-Means Clustering\n",
    "주어진 데이터를 k개의 클러스터로 묶는 알고리즘\n",
    "- 원리 : 군집화 알고리즘으로서, 각 군집은 중심을 가지며 같은 중심에 할당 된 데이터들이 하나의 군집을 형성 한다.\n",
    "(초기 중심 설정에 따라 결과 바뀔 수 있다)\n",
    "사전에 군집수가 결정이 되어야 알고리즘 실행이 가능하다. \n",
    "- 장단점 : 서로 다른 크기와 밀도의 군집 및 지역적 패턴이 존재하는 군집에 취약하다\n",
    "- 사용 : 군집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_KM = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KM.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 2, 2, 2, 1, 0, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0,\n",
       "       2, 1, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 2, 1, 2, 0,\n",
       "       1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 0, 2, 1, 0, 1,\n",
       "       2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 2])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KM.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_KM.predict(x_test)\n",
    "score = metrics.accuracy_score(result, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
